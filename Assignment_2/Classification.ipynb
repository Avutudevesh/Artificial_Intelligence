{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras import *\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib as mpl\n",
    "from keras import optimizers\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage.io import imsave, imread\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from scipy.misc import imresize\n",
    "from keras.layers.convolutional import Deconv2D as Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.layers import Add\n",
    "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "import sys\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "from keras.layers import Input, merge, Dropout, Dense, Lambda, Flatten, Activation\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "from keras import backend as K\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading done 2000 images.\n"
     ]
    }
   ],
   "source": [
    "resize_h=256\n",
    "resize_w=256\n",
    "\n",
    "def load_data():\n",
    "    total=len(os.listdir('melanoma/'))+len(os.listdir('others/'))\n",
    "    imgs=[]\n",
    "    imgs_mask=[]\n",
    "    labels=[]\n",
    "    i = 0\n",
    "    images = os.listdir('melanoma/')\n",
    "    for image_name in images:\n",
    "        image_mask_name = image_name.split('.')[0]\n",
    "        image_mask_name = image_mask_name+\"_segmentation.png\"\n",
    "        img = ndimage.imread('melanoma/'+image_name)       \n",
    "        img_mask = ndimage.imread('gt/'+image_mask_name)\n",
    "        labels.append(1)\n",
    "        img = img_to_array(img)\n",
    "        img_mask=img_to_array(img_mask)\n",
    "        img_mask=np.reshape(img_mask,(img_mask.shape[0],img_mask.shape[1],1))\n",
    "        img = np.multiply(img ,img_mask/255.)\n",
    "        img = imresize(img,(resize_h,resize_w))\n",
    "        imgs.append(img)\n",
    "        i += 1\n",
    "    images = os.listdir('others/')\n",
    "    for image_name in images:\n",
    "        image_mask_name = image_name.split('.')[0]\n",
    "        image_mask_name = image_mask_name+\"_segmentation.png\"\n",
    "        img = ndimage.imread('others/'+image_name)       \n",
    "        img_mask = ndimage.imread('gt/'+image_mask_name)\n",
    "        labels.append(0)\n",
    "        img = img_to_array(img)\n",
    "        img_mask=img_to_array(img_mask)\n",
    "        img_mask=np.reshape(img_mask,(img_mask.shape[0],img_mask.shape[1],1))\n",
    "        img = np.multiply(img ,img_mask/255.)\n",
    "        img = imresize(img,(resize_h,resize_w))\n",
    "        imgs.append(img)\n",
    "        i += 1\n",
    "    print('Loading 2000 images done')\n",
    "    imgs = np.array(imgs, dtype=\"float\")\n",
    "    imgs_mask = np.array(imgs_mask,dtype=\"float\")\n",
    "    labels = np.array(labels,dtype='float')\n",
    "    return imgs, labels\n",
    "\n",
    "X, Y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save( 'images.npy', X)\n",
    "np.save('labels.npy', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.load('../imgs_classify.npy')\n",
    "Y = np.load('../labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.67186529e-16,   2.22915381e-16, ...,\n",
       "         9.99998152e-01,   9.99998689e-01,   1.00000000e+00])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(X,Y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "\n",
    "    # Count positive samples.\n",
    "    c1 = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    c2 = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    c3 = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "\n",
    "    # If there are no true samples, fix the F1 score at 0.\n",
    "    if c3 == 0:\n",
    "        return 0\n",
    "\n",
    "    # How many selected items are relevant?\n",
    "    precision = c1 / c2\n",
    "\n",
    "    # How many relevant items are selected?\n",
    "    recall = c1 / c3\n",
    "\n",
    "    # Calculate f1_score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 256, 256\n",
    "nb_train_samples = 1600\n",
    "nb_validation_samples = 400\n",
    "nb_filters1 = 32\n",
    "nb_filters2 = 64\n",
    "conv1_size = 3\n",
    "conv2_size = 2\n",
    "pool_size = 2\n",
    "classes_num = 2\n",
    "batch_size = 64\n",
    "lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(nb_filters1, (conv1_size, conv1_size), padding=\"same\", input_shape=(img_width, img_height, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "model.add(Conv2D(nb_filters2, (conv2_size, conv2_size), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size), data_format='channels_first'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy', f1_score, precision, recall])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 64)      8256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 64, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               67109120  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 67,118,529\n",
      "Trainable params: 67,118,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint1 = ModelCheckpoint('simple_classification1.hdf5',monitor = 'loss', verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1568/1600 [============================>.] - ETA: 2s - loss: 0.8936 - acc: 0.7487 - f1_score: 0.5626 - precision: 0.4266 - recall: 0.9082\n",
      "Epoch 00001: loss improved from inf to 0.89969, saving model to simple_classification1.hdf5\n",
      "1600/1600 [==============================] - 120s 75ms/step - loss: 0.8997 - acc: 0.7488 - f1_score: 0.5624 - precision: 0.4281 - recall: 0.9025 - val_loss: 0.5673 - val_acc: 0.7700 - val_f1_score: 0.5392 - val_precision: 0.4442 - val_recall: 0.7341\n",
      "Epoch 2/50\n",
      "1568/1600 [============================>.] - ETA: 2s - loss: 0.5681 - acc: 0.8769 - f1_score: nan - precision: 0.6197 - recall: 0.9193\n",
      "Epoch 00002: loss improved from 0.89969 to 0.56406, saving model to simple_classification1.hdf5\n",
      "1600/1600 [==============================] - 123s 77ms/step - loss: 0.5641 - acc: 0.8762 - f1_score: nan - precision: 0.6190 - recall: 0.9209 - val_loss: 0.5688 - val_acc: 0.7600 - val_f1_score: 0.5378 - val_precision: 0.4407 - val_recall: 0.7592\n",
      "Epoch 3/50\n",
      " 352/1600 [=====>........................] - ETA: 1:26 - loss: 0.3410 - acc: 0.9545 - f1_score: 0.8558 - precision: 0.8231 - recall: 0.9545"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8afd38eacf37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/tmp/gated_cnn_autoencoder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_checkpoint1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/iplab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = model.fit(trainX,trainY, batch_size = 32, epochs = 50, verbose = True, validation_data = (testX, testY),callbacks=[TensorBoard(log_dir='/tmp/gated_cnn_autoencoder', histogram_freq=0,write_graph=True),model_checkpoint1],class_weight={0: 1, 1: 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,name = \"Cf.png\",\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig = plt.gcf()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig(name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = classifier>=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(a, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Non-Melanoma', 'Melanoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.86  0.14]\n",
      " [ 0.42  0.58]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAEmCAYAAAAnRIjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f739ed93490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes=class_names,normalize= True,\n",
    "                      name = \"NB_Confusion_matrix_without_normalisation.png\",\n",
    "                      title='Confusion matrix without Normalisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
